# The transport for the MCP server - either 'sse' or 'stdio' (defaults to SSE if left empty)
TRANSPORT=sse

# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=0.0.0.0

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=8050

# The provider for your LLM
# Set this to either openai, openrouter, ollama, or github_copilot
# This is needed on top of the base URL for Mem0 (long term memory)
LLM_PROVIDER=github_copilot

# Base URL for the OpenAI compatible instance (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
# OpenRouter: https://openrouter.ai/api/v1
# GitHub Copilot: No base URL needed - uses LiteLLM direct integration
LLM_BASE_URL=

# OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# Open Router: Get your API Key here after registering: https://openrouter.ai/keys
# GitHub Copilot: No API key needed - uses LiteLLM direct integration
# Ollama: No need to set this unless you specifically configured an API key
LLM_API_KEY=

# The LLM you want to use for processing memories.
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
# GitHub Copilot example: github_copilot/gpt-4o, github_copilot/gpt-4o-mini, github_copilot/claude-3-5-sonnet
# Ollama example: qwen2.5:14b-instruct-8k
LLM_CHOICE=github_copilot/gpt-4o

# The embedding model you want to use to store memories - this needs to be from the same provider as set above.
# OpenAI example: text-embedding-3-small
# GitHub Copilot example: github_copilot/text-embedding-3-small, github_copilot/text-embedding-3-large
# Ollama example: nomic-embed-text
EMBEDDING_MODEL_CHOICE=github_copilot/text-embedding-3-small

# Vector Store Configuration
# Set this to either 'qdrant' or 'supabase' (default is supabase)
VECTOR_STORE_PROVIDER=qdrant

# Qdrant Cloud Configuration (only needed if VECTOR_STORE_PROVIDER=qdrant)
# Get your cluster URL from: https://cloud.qdrant.io/
# Format: https://<cluster-id>.qdrant.io or https://<cluster-id>.<region>.aws.qdrant.io
QDRANT_URL=https://d18b9c8e-4c45-4c08-bbcb-af0ae88ddc91.us-west-2-0.aws.cloud.qdrant.io

# Qdrant API Key (get this from your Qdrant Cloud cluster settings)
QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.vwrLS4036uXjMC-8Pi_ueYWkLQUirpoWnQ7lKPVUAoU

# Qdrant Collection Name (optional, defaults to mem0_memories)
QDRANT_COLLECTION_NAME=mem0_memories

# Postgres DB URL used for mem0 (only needed if VECTOR_STORE_PROVIDER=supabase)
# Format: postgresql://[user]:[password]@[host]:[port]/[database_name]
# Example: postgresql://postgres:mypassword@localhost:5432/mydb
# For Supabase Postgres connection, you can find this in "Connect" (top middle of Supabase dashboard) -> Transaction pooler
DATABASE_URL=postgresql://postgres.hkeummfhryxuvhfmoeqo:YNvt7v6bEdsxlq6S@aws-1-us-west-1.pooler.supabase.com:6543/postgres

